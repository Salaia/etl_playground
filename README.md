Если меня занесло в данные, то надо продолжать работать с данными.
Мне мало проку изучать Django, а вот составить минимальный ETL-pipeline будет полезно.

<div>
<img width="1024" alt="A fairy girl puts pipes with help of python" src="data/landing_pipes_python.png">
</div>

Технические заметки:
* MySql DB, которую создала под учебник "Знакомьтесь, Питон!" - ради одной-двух таблиц делать отдельную базу не вижу смысла
* Инструменты - только знакомые. Питон, Пандас... не надо все яйца в одну корзину, с AirFlow я поиграю позже и отдельно
* Какие данные я буду собирать? user_name, email, source, pipe_time

Что я хочу сделать?

* (+) Получить данные по API - librarianmon рабочий, база запускается, по http://127.0.0.1:8182/ я до него достучалась и получила данные
* (+) Отпарсить *.csv
* (+) *.xml
* (-) Проверка дубликатов
* (+) Что-то дорисовать данным, например, указать их источник и timestamp загрузки в pipeline...
* (+) Сохранить все это в целевую базу

Заметки:
* Скрипт будет прям в файле main, потому что пока что мне нечего разбивать

Чего еще от меня хочет Сергей Васильевич:
* Изучить Jupiter Lab... концепт и стили оформления. В идеале мы хотим сделать документ с шаблонами скриптов по работе с БД для диагностики проблем. Чтобы этим можно было пользоваться в браузере, а что за скрипт - детали.